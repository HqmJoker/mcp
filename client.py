import asyncio
import os
import json
from typing import Optional
from contextlib import AsyncExitStack

from openai import OpenAI
from dotenv import load_dotenv

from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client

load_dotenv()

class MCPClient:
  # åˆå§‹åŒ–ä¿¡æ¯
  def __init__(self):
    """ åˆå§‹åŒ– MCP å®¢æˆ·ç«¯ """
    self.exit_stask = AsyncExitStack()
    self.openai_api_key = os.getenv("OPENAI_API_KEY")
    self.openai_base_url = os.getenv("BASE_URL")
    self.openai_model = os.getenv("MODEL")

    if not self.openai_api_key:
      raise ValueError("âŒ æœªæ‰¾åˆ° OpenAI API Keyï¼Œè¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½® OPENAI_API_KEY")

    self.client = OpenAI(api_key=self.openai_api_key, base_url=self.openai_base_url)

    if not self.client:
      raise ValueError("âŒ æ— æ³•åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯ï¼Œè¯·æ£€æŸ¥é…ç½®")
  # è¿æ¥å¯ç”¨mcpå·¥å…·
  async def connect_mcp_server(self, server_script_path: str):
    """ è¿æ¥åˆ° MCP æœåŠ¡å™¨å¹¶åˆ—å‡ºå¯ç”¨çš„mcpå·¥å…· """
    is_python = server_script_path.endswith(".py")
    is_js = server_script_path.endswith(".js")
    if not is_python and not is_js:
      raise ValueError("âŒ ä¸æ”¯æŒçš„æœåŠ¡å™¨è„šæœ¬æ ¼å¼ï¼Œè¯·ä½¿ç”¨ .py æˆ– .js æ ¼å¼çš„æ–‡ä»¶")
    command = "python" if is_python else "node"
    server_params = StdioServerParameters(
      command=command,
      args=[server_script_path],
      env=None
    )

    # å¯åŠ¨ MCP æœåŠ¡å™¨å¹¶å»ºç«‹é€šä¿¡
    stdio_transport = await self.exit_stask.enter_async_context(
      stdio_client(server_params)
    )
    self.stdio, self.write = stdio_transport
    self.session = await self.exit_stask.enter_async_context(
      ClientSession(self.stdio, self.write)
    )

    await self.session.initialize()
    print("\nâœ… å·²è¿æ¥åˆ° MCP æœåŠ¡å™¨")

    # åˆ—å‡ºå¯ç”¨çš„mcpå·¥å…·
    tools = await self.session.list_tools()
    print("\nå¯ç”¨çš„mcpå·¥å…·ï¼š", [tool.name for tool in tools])

  # å¤„ç†ç”¨æˆ·è¯·æ±‚
  async def process_query(self, query: str) -> str:
    """ ä½¿ç”¨å¤§æ¨¡å‹å¤„ç†æŸ¥è¯¢å¹¶è°ƒç”¨å¯ç”¨çš„ MCP å·¥å…· (Function Calling) """
    messages = [
      {"role": "user", "content": query}
    ]

    response = await self.session.list_tools()

    # æ ¼å¼åŒ–ä¸º OpenAI å¯è¯»å·¥å…·åˆ—è¡¨
    available_tools = [{
        "type": "function",
        "function": {
            "name": tool.name,
            "description": tool.description,
            "input_schema": tool.inputSchema
        }
    } for tool in response.tools]

    response = self.client.chat.completions.create(
        model=self.openai_model,            
        messages=messages,
        tools=available_tools     
    )

    # å¤„ç†è¿”å›çš„å†…å®¹
    content = response.choices[0]
    # å¦‚æœè¿”å›çš„å†…å®¹æ˜¯å‡½æ•°è°ƒç”¨ï¼Œåˆ™è°ƒç”¨å‡½æ•°
    if content.finish_reason == "tool_calls":
      tool_call = content.message.tool_calls[0]
      function_name = tool_call.function.name
      function_args = json.loads(tool_call.function.arguments)

      # è°ƒç”¨ MCP å·¥å…·
      tool_response = await self.session.call_tool(function_name, function_args)
      print(f"\n\n[Calling tool {tool_name} with args {tool_args}]\n\n")

      # å°†æ¨¡å‹è¿”å›çš„è°ƒç”¨å“ªä¸ªå·¥å…·æ•°æ®å’Œå·¥å…·æ‰§è¡Œå®Œæˆåçš„æ•°æ®éƒ½å­˜å…¥messagesä¸­
      messages.append(content.message.model_dump())
      messages.append({
          "role": "tool",
          "content": tool_response.content[0].text,
          "tool_call_id": tool_call.id,
      })
      # å°†ä¸Šé¢çš„ç»“æœå†è¿”å›ç»™å¤§æ¨¡å‹ç”¨äºç”Ÿäº§æœ€ç»ˆçš„ç»“æœ
      response = self.client.chat.completions.create(
          model=self.openai_model,
          messages=messages,
      )
      return response.choices[0].message.content
    
    return content.message.content

  async def chat_loop(self):
    """ è¿è¡Œäº¤äº’å¼èŠå¤©å¾ªç¯ """
    print("\nMCP å®¢æˆ·ç«¯å·²å¯åŠ¨ï¼Œè¾“å…¥ /quit é€€å‡º")

    while True:
      try :
        query = input("\nä½ : ").strip()
        if query.lower() == 'quit':
          break

        response = await self.process_query(query) # ç”¨æˆ·å‘é€æ¶ˆæ¯åˆ°OpenAI
        print(f"\nğŸ¤– OpenAIï¼š{response}")

      except Exception as e:
        print(f"âŒ å‘ç”Ÿé”™è¯¯ï¼š{str(e)}")
  async def cleanup(self):
    """ æ¸…ç† MCP å®¢æˆ·ç«¯çš„èµ„æº """
    await self.exit_stask.aclose()
    print("\nâœ… MCP å®¢æˆ·ç«¯å·²å…³é—­")    
async def main():
  if len(sys.argv) < 2:
    print("Usage: python client.py <path_to_server_script>")
    sys.exit(1)
  client = MCPClient()
  try :
    await client.connect_mcp_server(sys.argv[1])
    await client.chat_loop()
  finally :
    await client.cleanup()

if __name__ == "__main__":
  import sys
  asyncio.run(main())